import numpy as np
import tensorflow as tf
from tensorflow.examples.tutorials import mnist
import time
import os
from helper import *



class DRAW():

    def __init__(self, sess, read_attn = False, write_attn = False, T = 10, train_iters = 100, batch_size = 100):
        self.sess = sess


        self.DO_SHARE = None # workaround for variable_scope(reuse=True)
        self.data_dir = ""
        self.read_attn = read_attn
        self.write_attn = write_attn

        # Currently I just fix all the tuning parameters. Could be given as input arguments.
        ## MODEL PARAMETERS ##

        self.A, self.B = 28, 28 # image width,height
        self.img_size = self.B * self.A # the canvas size
        self.enc_size = 256 # number of hidden units / output size in LSTM
        self.dec_size = 256
        self.read_n = 5 # read glimpse grid width/height
        self.write_n = 5 # write glimpse grid width/height
        self.read_size = 2* self.read_n * self.read_n if self.read_attn else 2* self.img_size
        self.write_size = self.write_n * self.write_n if self.write_attn else self.img_size
        self.z_size=10 # QSampler output size
        self.T = T # MNIST generation sequence length
        self.batch_size=100 # training minibatch size
        self.train_iters = train_iters
        self.learning_rate=1e-3 # learning rate for optimizer
        self.eps=1e-8 # epsilon for numerical stability
        
        ## BUILD MODEL ## 
    

    def train(self):


        # Determine if we want to use 'attention' during reading and writing
        read = read_attn if self.read_attn else read_no_attn
        write = write_attn if self.read_attn else write_no_attn

        #---------------------------------------------------------------
        #---------------------------------------------------------------
        #---------------------------------------------------------------
        # Build Graph


        # Build graph:
        x = tf.placeholder(tf.float32,shape=(self.batch_size, self.img_size)) # input (batch_size * img_size)
        lstm_enc = tf.nn.rnn_cell.LSTMCell(self.enc_size, state_is_tuple=True) # encoder Op
        lstm_dec = tf.nn.rnn_cell.LSTMCell(self.dec_size, state_is_tuple=True) # decoder Op


        # ENCODE 
        def encode(state, input, reuse):
            """
            run LSTM
            state = previous encoder state
            input = cat(read,h_dec_prev)
            returns: (output, new_state)
            """
            with tf.variable_scope("encoder",reuse = reuse):
                return lstm_enc(input, state)

        # Decoder
        def decode(state, input, reuse):
            with tf.variable_scope("decoder",reuse= reuse):
                return lstm_dec(input, state)

        # Initialize variables
        self.cs = [0] * self.T # sequence of canvases
        mus, logsigmas, sigmas=[0] * self.T,[0] * self.T,[0] * self.T # gaussian params generated by SampleQ. We will need these for computing loss.
        # Initial states
        h_dec_prev = tf.zeros((self.batch_size, self.dec_size))
        enc_state = lstm_enc.zero_state(self.batch_size, tf.float32)
        dec_state = lstm_dec.zero_state(self.batch_size, tf.float32)

        # Construct the unrolled computational graph
        for t in range(self.T):
            # print t
            c_prev = tf.zeros((self.batch_size, self.img_size)) if t==0 else self.cs[t-1]
            x_hat = x-tf.sigmoid(c_prev) # error image
            r = read(x,x_hat,h_dec_prev, self.A, self.B, self.read_n, self.DO_SHARE, self.eps)
            h_enc, enc_state = encode(enc_state,tf.concat(1,[r, h_dec_prev]), reuse = self.DO_SHARE)
            z, mus[t], logsigmas[t], sigmas[t]=sampleQ(h_enc, self.DO_SHARE, self.batch_size, self.z_size)
            h_dec,dec_state=decode(dec_state, z,  reuse = self.DO_SHARE)
            self.cs[t] = c_prev + write(h_dec, self.DO_SHARE, self.write_n, self.A, self.B, self.eps, self.batch_size) # store results
            h_dec_prev = h_dec
            self.DO_SHARE = True # from now on, share variables


        ## Compute the loss

        def binary_crossentropy(t , o):
            return -(t * tf.log(o + self.eps) + (1.0 - t) * tf.log(1.0 - o + self.eps))

        # reconstruction term appears to have been collapsed down to a single scalar value (rather than one per item in minibatch)
        x_recons = tf.nn.sigmoid(self.cs[-1])

        # after computing binary cross entropy, sum across features then take the mean of those sums across minibatches
        Lx = tf.reduce_sum(binary_crossentropy(x, x_recons),1) # reconstruction loss
        Lx = tf.reduce_mean(Lx)

        kl_terms=[0] * self.T

        for t in range(self.T):
            mu2 = tf.square(mus[t])
            sigma2 = tf.square(sigmas[t])
            logsigma = logsigmas[t]
            kl_terms[t]=  0.5 * tf.reduce_sum(mu2 + sigma2 - 2 * logsigma, 1) - self.T * .5 # each kl term is (1xminibatch)

            
        KL = tf.add_n(kl_terms) # this is 1xminibatch, corresponding to summing kl_terms from 1:T
        Lz = tf.reduce_mean(KL) # average over minibatches

        cost = Lx + Lz

        ## OPTIMIZER ## 
        
        optimizer=tf.train.AdamOptimizer(self.learning_rate, beta1=0.5)
        grads=optimizer.compute_gradients(cost)
        for i,(g,v) in enumerate(grads):
            if g is not None:
                grads[i]=(tf.clip_by_norm(g,5),v) # clip gradients
        train_op=optimizer.apply_gradients(grads)
                
        ## RUN TRAINING ## 

        data_directory = os.path.join(self.data_dir, "mnist")
        if not os.path.exists(data_directory):
	    os.makedirs(data_directory)

        # binarized (0-1) mnist data

        train_data = mnist.input_data.read_data_sets(data_directory, one_hot=True).train 

        fetches=[]
        fetches.extend([Lx, Lz, train_op])
        self.Lxs=[0] * self.train_iters
        self.Lzs=[0] * self.train_iters
        
        sess = self.sess
        
        saver = tf.train.Saver() # saves variables learned during training
        tf.initialize_all_variables().run()
        #saver.restore(sess, "/tmp/draw/drawmodel.ckpt") # to restore from model, uncomment this line
        
        for i in range(self.train_iters):
	    xtrain,_ = train_data.next_batch(self.batch_size) # xtrain is (batch_size x img_size)
	    self.feed_dict = {x:xtrain}
	    results = sess.run(fetches, self.feed_dict)
	    self.Lxs[i], self.Lzs[i], _ = results
	    if i%100 == 0:
		print("iter=%d : Lx: %f Lz: %f" % (i, self.Lxs[i], self.Lzs[i]))

        self.saver = tf.train.Saver()


    def inference(self):
        canvases = self.sess.run(self.cs, self.feed_dict) # generate some examples
        canvases = np.array(canvases) # T x batch x img_size
        return canvases




